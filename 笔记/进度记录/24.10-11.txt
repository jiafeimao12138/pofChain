#### 10.7

学习完Vue基础知识

#### 10.11

设计上是完备的，写论文的时候只说设计上做了什么，不讲具体实现，只在性能评测上提一嘴

#### 10.25  

再试一次能否在窗口结束后正确复制testcase_file和testfile1。如果不行的话就不复制了，直接截断

经过readfile.py的测试，窗口的path和case数量相同

```
random_key=62142
	endbr64
	jle	.L15
random_key=719
	jbe	.L16
random_key=38927
	jne	.L3
random_key=15713
	je	.L17
random_key=10245
random_key=64764
	leaq	.LC3(%rip), %rdi
random_key=19876
	endbr64
	jne	.L21
random_key=53136

```

D226 D226 5F79 5F79 6701 6701 074C 074C 7E7E 7E7E C867

triple三元组完成

计算hash完成。结合pofChain计算hash完成。待验证

#### 10.26，10.27

银行线下笔试等等

#### 10.28

修改afl_exec.sh，web端运行起来

问题：web端运行发现case和path数量不匹配

解决：修改了web端的代码。把脚本改成直接执行命令。

问题：挂起后再恢复执行，path并不是从0000开始的，那么上轮的这个未完整记录path的testcase并没有在这轮被记录，这时候testcase应该加一，path也应该加一（因为之前算path数量的时候是从0000开始算的）所以path文件中第一条路径是上一个窗口的剩余路径，也就是说其他的case和path都是正确的匹配的

解决：添加上一个窗口最后一个case和它的path的记录，这两个变量需要持久性记录，可以存到一个文件中

~~问题：path写入record文件中时，二进制数据显示有错位~~

~~解决：确保在写入和读取时使用相同的字节序。可以使用 ByteBuffer 来明确指定字节序，指定小端序~~

> [!CAUTION]
>
> 问题：读取record文件中的case时，怎么转换成字符？现在是二进制字符串的形式
>
> 解决：不管了先二进制吧，后面再说

> [!IMPORTANT]
>
> 问题：为啥还是不匹配！！！淦！各种试了都会出现不匹配的情况
>
> 待解决

#### 10.29

招行面试，伤到了。。。

#### 10.30

p2p实现：tio框架的client和server搭建

#### 10.31

p2p进一步实现，填充了tio框架，加了hello消息 √

生成p2p相关信息文件，读取port、address等信息 √

​	运行jar包启动时参数：--spring.config.location、--repo、--genesis、--api.port、--p2p.port

先启动创世节点 √

问题：多模块打包jar包报错，找不到引用的类

解决：pom文件没写对，可参考https://blog.csdn.net/qq_35387940/article/details/109067973

jar包可以运行了 √

#### 11.1

面了3场，伤不起啊。。。

p2p可以连接别的节点 √

广播Block

问题：创世节点运行时，tio报错 java.net.ConnectException: 拒绝连接

解决：运行时加入--spring.config.location指定配置文件的位置，配置文件中有address和port，P2pNetConfig中通过@Value读取

```java
java -jar pof-miner/target/pof-miner-0.0.1-SNAPSHOT.jar genesis -repo=./datastore/genesis --spring.config.location=./datastore/genesis/node.properties
    
java -jar pof-miner/target/pof-miner-0.0.1-SNAPSHOT.jar mine -repo=./datastore/miner1  --spring.config.location=./datastore/miner1/node.properties -api.port=8002 -p2p.port=3456
```

#### 11.2

打包好要广播的内容√

修改Block类的变量√

添加NewBlockEvent事件、NewMsgEvent事件√

所有代码上传github√

问题：github文件夹有白色箭头并且不能打开的解决办法 √

解决：

```
原来是因为这个文件夹里面有.git隐藏文件，github就将他视为一个子系统模块了。
解决办法就是：
1、删除文件夹里面的.git文件夹
2、执行git rm --cached [文件夹名]
3、执行git add [文件夹名]
4、执行git commit -m "msg"
5、执行git push origin [branch_name] 
```

问题：github上传完整个项目结构乱了，得重组 √

解决：删除.idea文件夹，project structure重新添加3个模块，重命名3个模块

创世节点广播Block （目前只考虑创世节点一个节点挖矿的情况）√



问题：运行非创世节点时，报错Could not resolve placeholder 'p2p.address' in value "${p2p.address}"

解决：检查命令是不是写错了

问题：publishEvent报错空指针异常，context为null

解决：ApplicationContextProvider类没有加@Component注解

问题：BlockService空指针异常

解决：BlockService引用时不加autowired的话要以final定义并在构造函数中初始化

​	

#### 11.3

其他节点接收到REQ_NEW_BLOCK消息

​	只使用publishEvent广播消息是不够的，接收方需要方法去处理广播的消息才行，在BlockEventListener中定义消息类型

问题：怎么广播的内容其他节点收不到 √

解决：已经能够接收到新message了

添加开始挖矿的请求（controller层的请求）√

问题：miner空指针异常 √

原因：没有注入，需添加Autowired注解



#### 11.4

本地区块链的添加（先只处理创世区块的）：

1. 查询前一个区块 √

   问题：如何通过区块高度查询RocksDB中的区块 √

   解决：可以在RocksDB中维护一个单独的键，用于跟踪最新高度

   问题：查询前一个区块的时候空指针 √

   原因：方法返回值返回错了

3. 可以添加新区块到本地区块链 √

   问题：rocksDB存入没有可用的锁  

   解决：repo有问题？？？怎么还没解决，要记得close。要改后端fuzzing的结构



#### 11.5

问题：getLatestBlock方法从rocksDB获取某高度的block失败 √

原因：之前的操作把rocksdb close了，不能close

问题：获取某高度的block发现报错“找不到该高度的区块” √

原因：Triple反序列化出错，说是没有无参构造器

解决：为啥一定要用这个三元组呢？？？？用List不是一样！！！！啊偶，好像不行，类型不一样。创建了一个对象Payload来替代Triple，可以了

#### 11.6

创世区块挖矿结果：

```
Successfully create genesis block and store in database. Hash is 47203c5df691485413b058ab1cfd224d22e7d99b51c9c69dc90025d602c61856.
挖矿成功，新区块高度为2，hash=510f7a14065738e066908125597029cc91e105c049d26702bad9fec09cf814e8，前一个区块hash=47203c5df691485413b058ab1cfd224d22e7d99b51c9c69dc90025d602c61856
挖矿成功，新区块高度为3，hash=2a6693fc67f6a3f32bc1f6a8f151c06d66bf50bfacfe191e71b65869bf930743，前一个区块hash=510f7a14065738e066908125597029cc91e105c049d26702bad9fec09cf814e8
挖矿成功，新区块高度为4，hash=cc4c86245ff0b2a10fda8f9f4923cf95f7b7b979c11456fe36b2ad794f284325，前一个区块hash=2a6693fc67f6a3f32bc1f6a8f151c06d66bf50bfacfe191e71b65869bf930743
```

功能点：可以使用高度索引查询本地区块链 √

功能点：新节点加入连接 √

​	创世节点首先连接，然后将新节点广播给连接自己的所有节点 √

​	问题：第三个节点连接的时候，只能连接到创世区块，不能连接到第二个节点 √

​	原因：似乎没有写新节点加入的事件处理

​	解决：添加新节点事件处理、PeerService

​	问题：miner1运行时连rocksDB错误，还是有锁的问题 √

​	原因：锁又没释放

新消息广播，这三个节点都测试过了，都可以接收到对方的消息

创世节点：

![image-20241106203540591](C:\Users\21874\AppData\Roaming\Typora\typora-user-images\image-20241106203540591.png)

miner1

![image-20241106203609359](C:\Users\21874\AppData\Roaming\Typora\typora-user-images\image-20241106203609359.png)

miner2

![image-20241106203701469](C:\Users\21874\AppData\Roaming\Typora\typora-user-images\image-20241106203701469.png)

功能点：其他节点接收到广播的区块 √

​	问题：其他节点接收不到广播的区块  √

​	原因：发现创世节点广播的event其他节点都收不到，但其他节点广播的创世节点可以收到，是上一个功能点没有完成的原因

​	---问题：发现生成窗口文件的速度过快，而计算hash的速度过慢

添加了执行switchRoot.sh的代码 √

功能点：其他节点校验新区块的有效性：

1. 新区块的高度必须大于已有区块
2. 校验Hash值是否在给定范围内
3. 校验这个Block的preHash是否和自己本地的一样
4. 校验完毕后添加到本地区块链
5. 广播该区块

```
▷ 区块的数据结构语法上有效 
▷ 区块头的哈希值小于目标难度（确认包含足够的工作量证明） 
▷ 区块时间戳早于验证时刻未来两个小时（允许时间错误） 
▷ 区块大小在长度限制之内 
▷ 第一个交易（且只有第一个）是coinbase交易 
▷ 使用检查清单验证区块内的交易并确保它们的有效性，即1中的交易验证
▷ “交易的独立校验”一节已经讨论过这个清单。
```

#### 11.7

摆烂

#### 11.8

问题：发现triples每次窗口都增加 √

原因：每轮窗口结束后triples要清空啊，不然就累加了

和赵老师讨论 √

#### 11.9

复盘和老师的讨论

想法：一开始的话新路径肯定会特别多，如果按照一条路径计算一次hash的想法来看的话，会非常拥挤，因此设定为在执行窗口结束后，看窗口中运行的各路径计算出的hash值有多少条落在hash区间里面，多者取胜

#### 11.10

因为出块时间短，遇到了网络延迟，就会导致短时间内很多的节点同时算出了目标值得到了记账权，这样就产生了很多**分叉**，这对系统的安全性没有好处。

需要解决的难题：区间和新路径的hash映射关系是不清楚的

#### 11.11

去创新港上课，在51job投了50份简历

#### 11.12

和老师讨论

> [!NOTE]
>
> 一开始出块多会分叉的问题要和小齐讨论
>
> 也就是说为什么不能太快出块，为什么比特币要设置出块时间为10分钟

hash函数在计算路径时分布是否均匀，需要研究一下Hash函数，为什么bitcoin能确保10分钟内能出块？是因为它确定hash分布是均匀的吗

pow为什么能保证一定获得解？

 做实验看每个窗口计算出来的hash是否是分布均匀的：

1. 输出文件太多了，设置为每处理20个窗口文件，把已经处理过的删掉 √

2. 设置目标区间为全集的1/2，看最后落在这个区间的概率是否也为1/2 ，区间头为随机产生的256bit数，同理进行1/3的实验，先各实验1小时，每次挖矿成功后区块头需要变化吗？（可以都试试）

   为什么要变化呢？比特币也没有变，只有过了2016个块之后才会变

3. 将命中次数和全部次数存入文件中 √

> [!CAUTION]
>
> 问题：path文件全部只有20字节且内容一样
>
> 原因：直接用afl-fuzz指令没问题，根据之前的观察，有可能是读取文件比生成还快？？不应该啊。。。好像真是这个原因，因为我把输出line那行注释了，那就先取消注释吧，之后再看看怎么完全解决

####  11.13

继续改代码做实验：

1. 生成区间，区间头是随机生成的，区块长度根据想要多长时间挖到区块决定 √

2. 完善存入文件的代码，等待实验完成后用python画图 √

3. python编写处理结果文件的程序

4. 实验：想要1min左右挖出区块，设置区块长度为2^250

   ```
   2024-11-13 15:39:14.596 开始进行Fuzzing挖矿
   2024-11-13 15:39:19.003 第一个窗口的hash计算出的时间
   ```

5. 画出命中次数和全部次数的统计图，记录每次出块时间，计算平均出块时间

> [!WARNING]
>
> 问题：在运行到2334个文件的时候，cases_list.get(cases_list.size()-1)报错ArrayIndexOutOfBoundsException: -1
>
> 原因：猜想cases_list为空，已经添加了这个异常，如果下次再遇到会抛出异常，猜想原因是java处理得太快了？要修改一下java处理文件的代码，等下一个文件出来的时候再处理上一个文件，确保上一个文件在被处理的时候是完整的。

问题：动了python导致ubuntu重启进入图形化界面失败了。。。。

解决：回到快照了，妈的浪费我两小时，以后用python全部迁到windows完成

#### 11.14

安装python、pycharm √

使用matplotlib画命中次数和全部次数关系的统计图，呈线性关系 √

画出出块时间和预期的对比图，平均出块和预期出块误差10% √

挖矿难度增加，虚拟机带不动了，崩溃了好几次。。。

修改了一下java处理窗口文件的代码，AFL输出增加一个num值，这样确保处理的文件和num一样 √

比特币设置出块时间为10分钟，但是实际上每次挖矿时间相差蛮大的，快的十几秒，慢的20分钟

> [!CAUTION]
>
> 存在每20个清理一批但是该批没有被清理的情况，不应该漏掉啊。。。

#### 11.15

输出每个block中的payload数量看一下 √

问题：11.13出现的问题，成功捕获到异常了，但具体原因是这两个文件直接是空的，也就是说这个执行窗口中根本没有执行任何测试用例，这合理吗？可能是AFL的问题，不管怎么说，先让它能够运行下去不要断开，那处理一下这个情况，忽略这个异常

<img src="C:\Users\21874\AppData\Roaming\Typora\typora-user-images\image-20241115103434253.png" alt="image-20241115103434253" style="zoom: 50%;" />

<img src="C:\Users\21874\AppData\Roaming\Typora\typora-user-images\image-20241115103459658.png" alt="image-20241115103459658" style="zoom:50%;" />

> [!IMPORTANT]
>
> 问题：运行的时候会出现卡住一段时间的情况，AFL还是正常在输出结果文件，会导致AFL待处理文件越来越多。这个卡住的时间也很难说，可能会卡很久
>
> 原因：猜想java获取AFL输出的这个方法有问题，可以换一种方法，监控文件

matplotlib画结果图，分别为目标出块时间64、128、256s √

bitcoin是如何从Mempool中选择要打包的交易的？

bitcoin中的coinbase是什么？是特殊类型的交易，用于奖励矿工挖矿成功，是区块中的第一笔交易

#### 11.16

把3个实验（64s，128s，256s）的实验结果整理一下

和小赵讨论

#### 11.17

看bitcoin源码

多个节点竞争挖矿的功能

1. 新节点加入网络后，向其他节点请求同步区块链，新节点会逐步下载所有区块，直到与现有区块链完全同步
2. 先请求当前网络中区块链的区块头，以获取区块链的高度和最新区块的信息
3. 处理接收到的区块：新节点在同步区块时，也要对区块进行验证
   - [ ] 当节点正在导入区块时，忽略接收到的区块消息，并记录日志，这样做是为了避免在导入过程中处理新的区块，防止潜在冲突
   - [ ] 记录接收的区块的日志，显示接收到的区块的hash值和发送该区块的peer id
4. 访问区块链时要加锁，以保证多线程访问共享数据的安全

#### 11.18

去创新港，中兴星云面试，不幸感冒

#### 11.19

和小齐小赵讨论，感冒加重，头疼

#### 11.20

感冒头疼，去医院

#### 11.21

学习bitcoin源码并记录文档，记录在"D:\111毕设\笔记\区块链.docx"

差不多搞清楚了比特币挖矿

贴个github学习地址：https://github.com/bitcoinbook/bitcoinbook/tree/develop	

和小赵说了比特币源码中没有看到确保能够一定挖到矿的机制，小赵说那就按照之前说的来（即不要原来的动态可变映射哈希区间算法）

#### 11.22

添加新路径的判断：
每个窗口结束后要判断新路径的数量，要根据新路径分配奖励，那么该怎么判断新路径呢？这里的新路径是全网的新路径，这样一来为了判断是否是新路径，每个节点都要存储所有新路径的副本，这现实吗？

问了小赵，还真是这样，需要每个节点都存储全网的新路径，至于如果路径太多会太大的问题，可接受范围，因为块是由数字表示的，所以占空间应该也不是特别大，存在程序发布者的那个地方，相当于汇报给程序发布者，虽然我们这个区块链是分布式的，但是有一个程序发布这么一个平台，矿工需要在这个平台接任务。

#### 11.23

- [x] 拆分Block类为BlockHeader和Block
- [x] 重构ChainService和BlockService，把方法拆解出来，重命名BlockService为MiningService
- [x] 新节点加入网络后，向其他节点请求同步区块链，新节点会逐步下载所有区块，直到与现有区块链完全同步，同步区块链的方法采用每次请求一个区块，接收后再请求下一个高度的区块
  - [x] 添加REQ_BLOCKS事件和处理逻辑
    1. 在MessageType中添加REQ_BLOCKS和RES_BLOCKS
    2. 在events中添加GetBlocksEvent事件
    3. 在listener中监听GetBlockEvent事件
    4. P2pServerHandler中处理该事件
    5. MessageServerHandler中写处理的具体逻辑
- [x] 同步区块链请求改成controller层发起的请求
- [ ] 结果要返回给前端，涉及到websocket技术



#### 11.24

- [x] 添加PacketMsgType枚举类，修改PacketBody
- [x] 修改了Block类里Hash值的赋值
- [x] 添加RES事件的处理逻辑（接上）
  6. P2pClientHandler中处理RES消息
  7. MessageClientHandler中写处理的具体逻辑
- [x] 校验新区块添加校验规则：区块高度过高舍弃
- [x] 添加新事件：获取当前主链最高的高度
- [x] 普通矿工节点创建时自动存储创世区块
- [x] controller层添加请求本地区块链最新的区块
- [x] 测试获取本地区块链中最高的区块功能
- [x] 测试功能：向其他peer请求主链最新高度
  - [x] 要加回调，因为有异步事件，懒得搞了，直接睡眠1s
- [x] 同步区块功能测试
- [x] 确定存储新路径的方法：采用键值对存储，“path/hash/timestamp: path”的形式，这里的hash是path计算得到的，如果hash值相等，进一步检查path是否相同，如果path不同，还没想好
  矿工接收到其他矿工发来的block时，检查block里的path，先对path做去重，接着搜索本地维护的新路径副本，本地没有的路径把它标记为新路径，存入副本中，将该矿工标记的新路径和block一起打包广播
  新节点加入同步区块的时候，也需要同步路径副本，当然如果是轻节点可以只同步hash，path先取空，当遇到hash碰撞的时候再向
  peer请求具体的path进行判断
  分发奖励的时候，参考的就是别的矿工认可的新路径

```
java -jar pof-miner/target/pof-miner-0.0.1-SNAPSHOT.jar genesis -repo=./datastore/genesis --spring.config.location=./datastore/genesis/node.properties
    
java -jar pof-miner/target/pof-miner-0.0.1-SNAPSHOT.jar miner -repo=./datastore/miner1  --spring.config.location=./datastore/miner1/node.properties -api.port=8002 -p2p.port=3456
```

#### 11.25

- [ ] 当矿工挖矿成功后，该矿工将新区块广播，并且新区块中的payload(input,path,iscrash)也一起广播，但是其他没有落在区间里的矿工所探索的路径全部浪费，只有这个获胜者的路径有用，这显然违背了初衷。
  或许可以这样：
  每次新区块成功添加到区块链中之后，每个矿工将该阶段挖掘出的新路径提交给程序供应商，由供应商方判定是否为新路径（如果两个人探索了相同的路径，则先到先得）。为了减少供应商方工作量，每个矿工在提交之前就先对自己本次探索的所有路径做去重操作，并与本地已经存在的副本比较，筛选出新路径，然后再提交。如果没有新路径则不提交。
  供应商方判定完毕后（这样一来供应商需要瞬间处理大量请求），将所有判定成功的新路径加入到新路径列表中，生成本轮的贡献度排名 ，并分发奖励。
  各矿工节点便可向供应商方请求更新后的新路径并更新本地副本
  这样一来设定的目标挖矿时间不能太短，至少需要长于区块网络传播时间和供应商方判定新路径的时间之和
  
  问题：这是一个激励探索新路径的区块链，那么探索到新路径的奖励需要大于挖掘出区块的奖励，这个区块链记载的好像没太大意义？比特币作为一个分布式账本，记账是它的主要目标，因此每个区块中存放的交易是它的主要任务；所以关于Fuzz的话，每个区块中需要能够体现出本轮所有的新路径。对标比特币的交易的话，那么每个矿工每发现一条新路径就广播？
  
- [ ] merkle树实现



